{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"ImagingFormats/","title":"Medical Image Formats","text":""},{"location":"ImagingFormats/#introduction","title":"Introduction","text":"<p>A medical image is a digital representation of the internal structure or function of an anatomic region, typically presented as an array of picture elements called pixels (2D) or voxels (3D). This representation is a discrete mapping of numerical values to positions in space.</p>"},{"location":"ImagingFormats/#medical-image-metadata","title":"Medical Image Metadata","text":"<p>Medical images often come with metadata, which provides additional information about the image. This metadata is usually stored at the beginning of the image file as a \"header.\"</p>"},{"location":"ImagingFormats/#common-metadata-fields","title":"Common Metadata Fields","text":"<ul> <li>Image dimensions: Width, height, depth</li> <li>Voxel size: Spacing between voxels</li> <li>Origin: Location of the first voxel</li> <li>Orientation: Direction of x, y, and z axes</li> <li>Pixel depth: Bytes used to represent each voxel intensity</li> <li>Data type: Integer, floating-point, etc.</li> </ul> <p>add diagram showing a sample header with key metadata fields</p>"},{"location":"ImagingFormats/#pixel-data","title":"Pixel Data","text":"<p>The pixel data in a medical image file represents the actual image values, stored in a format specific to the image file.</p> <ul> <li>In fixed-size header formats, pixel data follows the header directly.</li> <li>In other formats, a marker or tag indicates the start of pixel data.</li> </ul>"},{"location":"ImagingFormats/#pixel-data-size","title":"Pixel Data Size","text":"\\[ \\text{Pixel Data Size} = \\text{Rows} \\times \\text{Columns} \\times \\text{Pixel Depth (Bytes)} \\times \\text{Number of Frames} \\]"},{"location":"ImagingFormats/#image-file-size","title":"Image File Size","text":"\\[ \\text{Image File Size} = \\text{Header Size} + \\text{Pixel Data Size} \\] Example Calculation: <p>For a DICOM image with the following parameters:</p> Parameter Value Rows 512 Columns 512 Pixel Depth 2 bytes (16-bit image) Number of Frames 32 (32 slices) \\[ \\text{Pixel Data Size} = 512 \\times 512 \\times 2 \\times 32 = 16,777,216 \\text{ bytes (or 16 MB)} \\] <p>Assuming the header size for this DICOM file is 1,024 bytes:</p> \\[ \\text{Image File Size} = 1,024 \\text{ bytes} + 16,777,216 \\text{ bytes} = 16,778,240 \\text{ bytes (or 16.01 MB)} \\]"},{"location":"ImagingFormats/#medical-image-file-formats","title":"Medical Image File Formats","text":""},{"location":"ImagingFormats/#categories-of-medical-image-formats","title":"Categories of Medical Image Formats","text":"<ol> <li> <p>Standardization Formats: Standardize images from diagnostic modalities.</p> <ul> <li>Example: DICOM</li> </ul> </li> <li> <p>Post-Processing Formats: Facilitate and strengthen post-processing analysis.</p> <ul> <li>Examples: Analyze, NIfTI, MINC</li> </ul> </li> </ol>"},{"location":"ImagingFormats/#configurations-for-storing-medical-images","title":"Configurations for Storing Medical Images","text":"<ul> <li> <p>Single File: Contains both metadata and image data, with metadata stored   at the beginning.</p> <ul> <li>Examples: DICOM, MINC, NIfTI</li> </ul> </li> <li> <p>Two Files: Metadata and image data stored separately.</p> <ul> <li>Example: Analyze (.hdr and .img)</li> </ul> </li> </ul> <p>add diagram comparing single file vs. two-file configurations</p>"},{"location":"ImagingFormats/DICOM/","title":"DICOM (Digital Imaging and Communications in Medicine)","text":"<p>TODO: add introduction to DICOM</p> <p>TODO: Add references if using images from online </p> <p></p> <p></p>"},{"location":"ImagingFormats/nifti/","title":"Nifti Format","text":"<p>https://nipy.org/nibabel/coordinate_systems.html https://nipy.org/nibabel/nifti_images.html NIFTI first poster: https://nifti.nimh.nih.gov/nifti-1/documentation/hbm_nifti_2004.pdf NIfTI structure diagram: https://nifti.nimh.nih.gov/nifti-1/documentation/nifti1diagrams_v2.pdf</p>"},{"location":"ImagingFormats/nifti/#introduction-to-nifti","title":"Introduction to NIfTI","text":"<p>The NIfTI (Neuroimaging Informatics Technology Initiative) format is a derivative of the ANALYZE format, which was originally developed for medical imaging.</p>"},{"location":"ImagingFormats/nifti/#why-nifti","title":"Why NIfTI?","text":"<p>Before NIfTI, medical imaging data was stored in a variety of formats,  including ANALYZE, MINC, and DICOM.</p> <ul> <li>ANALYZE<ul> <li>ANALYZE is a proprietary format developed by the Mayo Clinic.</li> <li>ANALYZE files are not widely supported and are often difficult to work with.</li> </ul> </li> <li>MINC<ul> <li>MINC (Medical Image NetCDF) is a newer format developed by the National  Institutes of Health (NIH).</li> <li>MINC files are widely supported and can be easily shared and distributed.</li> </ul> </li> <li>DICOM<ul> <li>DICOM (Digital Imaging and Communications in Medicine) is a standardized  format for medical imaging data.</li> <li>DICOM files are widely supported and can be easily shared and distributed.</li> </ul> </li> </ul>"},{"location":"ImagingFormats/nifti/#references","title":"References","text":"<ol> <li>Medical Image File Formats, Michele Larobina, 2014.</li> <li>https://brainder.org/2012/09/23/the-nifti-file-format/</li> <li>http://www.cognitive-antics.net/2014/03/04/nifti-plain-and-simple/</li> </ol>"},{"location":"Introduction/ImageNet/","title":"ImageNet: Transforming Computer Vision","text":"<p>This content was written by an LLM</p> <p>This content was written by an LLM and requires a thorough review and editing to ensure accuracy and relevance before publishing.</p>"},{"location":"Introduction/ImageNet/#overview-what-is-imagenet","title":"Overview: What is ImageNet?","text":"<p>ImageNet is a massive visual database created for use in visual object recognition research. With over 14 million labeled images across thousands of categories, ImageNet serves as the backbone for many advancements in computer vision.</p> <p>TODO: add image/diagram of ImageNet categories and dataset structure</p>"},{"location":"Introduction/ImageNet/#the-impact-of-imagenet-on-computer-vision","title":"The Impact of ImageNet on Computer Vision","text":""},{"location":"Introduction/ImageNet/#a-benchmark-for-innovation","title":"A Benchmark for Innovation","text":"<p>ImageNet set a new standard for comparing and evaluating the performance of image recognition algorithms. By establishing a consistent benchmark, ImageNet fostered rapid advancements across the field of computer vision.</p>"},{"location":"Introduction/ImageNet/#the-imagenet-large-scale-visual-recognition-challenge-ilsvrc","title":"The ImageNet Large Scale Visual Recognition Challenge (ILSVRC)","text":"<p>The annual ILSVRC competition has been a major driver of progress. Each year, researchers compete to push the boundaries of image recognition, leading to breakthroughs that have revolutionized AI and deep learning. These innovations have gone beyond image recognition, impacting diverse fields in artificial intelligence and machine learning.</p> <p>TODO: add image/diagram of ILSVRC competition timeline and key milestones</p>"},{"location":"Introduction/ImageNet/#key-breakthroughs-powered-by-imagenet","title":"Key Breakthroughs Powered by ImageNet","text":""},{"location":"Introduction/ImageNet/#alexnet-the-catalyst-for-cnns-2012","title":"AlexNet: The Catalyst for CNNs (2012)","text":"<ul> <li>Achievement: First deep CNN to win ILSVRC, showcasing the potential of   convolutional neural networks (CNNs) for image classification.</li> <li>Impact: Paved the way for CNN architectures, proving their power on a   large-scale dataset.</li> </ul> <p>TODO: add image/diagram of AlexNet architecture</p>"},{"location":"Introduction/ImageNet/#vggnet-deep-networks-simplified-2014","title":"VGGNet: Deep Networks Simplified (2014)","text":"<ul> <li>Achievement: VGGNet demonstrated that increasing network depth can   improve performance.</li> <li>Key Feature: Simple and uniform architecture that added depth without   complexity.</li> </ul> <p>TODO: add image showing VGGNet depth and structure</p>"},{"location":"Introduction/ImageNet/#resnet-the-power-of-residual-learning-2015","title":"ResNet: The Power of Residual Learning (2015)","text":"<ul> <li>Achievement: Introduced the concept of residual connections, making it   possible to train ultra-deep networks.</li> <li>Impact: Enabled breakthroughs in deep learning by overcoming vanishing   gradient issues.</li> </ul> <p>TODO: add image/diagram of residual learning concept in ResNet</p>"},{"location":"Introduction/ImageNet/#yolo-you-only-look-once-real-time-object-detection-2016","title":"YOLO (You Only Look Once): Real-time Object Detection (2016)","text":"<ul> <li>Achievement: Developed a highly efficient real-time object detection   system that uses pre-trained ImageNet models.</li> <li>Impact: Revolutionized object detection, making it faster and more   accessible for applications.</li> </ul> <p>TODO: add image/diagram of YOLO\u2019s object detection in action</p>"},{"location":"Introduction/ImageNet/#mobilenet-lightweight-models-for-mobile-applications-2017","title":"MobileNet: Lightweight Models for Mobile Applications (2017)","text":"<ul> <li>Achievement: Optimized for mobile and embedded devices, leveraging   ImageNet for efficient image recognition.</li> <li>Impact: Brought advanced image recognition to mobile applications,   enabling real-time processing on low-power devices.</li> </ul> <p>TODO: add image/diagram of MobileNet architecture and mobile applications</p>"},{"location":"Introduction/ImageNet/#conclusion-the-lasting-influence-of-imagenet","title":"Conclusion: The Lasting Influence of ImageNet","text":"<p>ImageNet has been foundational in developing computer vision and deep learning technologies. Its role in creating a common benchmark and encouraging innovation through the ILSVRC has led to innovations that extend far beyond image recognition, impacting diverse areas of AI and machine learning. The dataset's influence will continue to shape the landscape of computer vision for years to come.</p> <p>TODO: add image summarizing the impact of ImageNet on AI and machine learning fields</p>"},{"location":"Introduction/ImageNet/#extra-resources","title":"Extra Resources","text":"<ul> <li>ImageNet: A Large-Scale Hierarchical Image Database</li> <li>ImageNet Large Scale Visual Recognition Challenge (ILSVRC)</li> <li>ImageNet: A Large Scale Hierarchical Image Database</li> <li>ImageNet: A Large Scale Hierarchical Image Database</li> </ul>"},{"location":"Overview/","title":"Med-ImageNet: Open-source Medical Imaging Data Curation for Large-scale AI","text":""},{"location":"Overview/#project-description","title":"Project Description","text":"<p>Med-ImageNet is a transformative initiative to create an open-access, standardized medical imaging dataset for cancer research and clinical AI applications.</p> <ul> <li>build tools for data curation and standardization</li> <li>enable reliable AI models for tumor segmentation and treatment monitoring</li> <li>design a standard in radiological imaging data accessibility</li> <li>promote equitable access to healthcare data for AI research</li> <li>foster collaboration and innovation in the AI-driven cancer research community</li> </ul>"},{"location":"Overview/#key-information","title":"Key Information","text":"<ul> <li>\ud83d\uddbc Project Title: Med-ImageNet</li> <li>\ud83e\uddec Objective:  Standardize and curate oncology imaging data to support AI-driven cancer research, focusing on auto-segmentation, treatment planning, and monitoring.</li> <li>\ud83c\udf10 Significance: Tackles the lack of standardized healthcare imaging data, making data FAIR (Findable, Accessible, Interoperable, and Reusable) for machine learning applications.</li> <li>\ud83d\udcbb Innovations: Develops MedImage-Tools for data standardization, providing a comprehensive, open-source dataset for cancer imaging.</li> <li>\ud83c\udf0d Equity and Inclusion: Prioritizes data inclusivity by representing diverse populations in cancer research.</li> </ul>"},{"location":"Overview/AI_Applications/","title":"AI Applications in Medical Imaging","text":""},{"location":"Overview/AI_Applications/#auto-segmentation-and-labeling","title":"Auto-Segmentation and Labeling","text":"<ul> <li>Automated Segmentation: Utilize Med-ImageNet data to train models that   can perform automatic segmentation of tumors and relevant structures within   medical images, reducing the time and effort required for manual labeling.</li> <li>Annotation Accuracy: Ensure that auto-segmentation tools produce precise   and clinically relevant boundaries, enhancing the quality of downstream AI   applications.</li> <li>Model Validation: Implement rigorous validation processes to assess the   reliability and accuracy of segmentation models, making them suitable for   clinical and research applications.</li> </ul>"},{"location":"Overview/AI_Applications/#treatment-planning-and-monitoring","title":"Treatment Planning and Monitoring","text":"<ul> <li>AI-driven Planning: Enable AI models trained on Med-ImageNet data to   support personalized treatment planning by identifying key anatomical   features and potential risks.</li> <li>Patient Monitoring: Leverage imaging data to monitor treatment progress   and detect early signs of relapse or treatment response, enabling timely   interventions.</li> <li>Outcome Prediction: Develop models that use imaging features to predict   patient outcomes, supporting oncologists in making data-driven treatment   decisions.</li> </ul>"},{"location":"Overview/AI_Applications/#open-ml-challenge-for-head-and-neck-cancer","title":"Open ML Challenge for Head and Neck Cancer","text":"<ul> <li>Challenge Objective: Host a public machine learning challenge focused on   head and neck cancer segmentation and analysis to encourage innovation and   improve model accuracy.</li> <li>Data Access and Submission: Provide participants with access to   anonymized Med-ImageNet data for training and testing, with submissions   evaluated on segmentation accuracy and clinical relevance.</li> <li>Advancing Model Generalizability: Use the challenge to identify models   that generalize well across diverse data, with high potential for clinical   implementation.</li> </ul>"},{"location":"Overview/Methodology/","title":"Methodology","text":""},{"location":"Overview/Methodology/#data-collection-and-curation-process","title":"Data Collection and Curation Process","text":"<ul> <li>Source Identification: Identify and collect diverse imaging data from   trusted sources, ensuring a broad representation of cancer types and   demographic groups.</li> <li>Data Cleaning and Preprocessing: Implement rigorous data cleaning to   remove inconsistencies and prepare images for standardized processing.</li> <li>Annotation Standards: Apply consistent annotation protocols across all   datasets, with expert validation to ensure quality and reliability.</li> </ul>"},{"location":"Overview/Methodology/#medimage-tools-development","title":"MedImage-Tools Development","text":"<ul> <li>Tool Design: Develop tools that streamline the standardization process,   allowing researchers to easily convert raw imaging data into a format   compatible with Med-ImageNet standards.</li> <li>Automation and Scalability: Design MedImage-Tools with automation   capabilities to handle large-scale data efficiently, ensuring the dataset   remains up-to-date with minimal manual intervention.</li> </ul>"},{"location":"Overview/Methodology/#integration-of-fair-principles","title":"Integration of FAIR Principles","text":"<ul> <li>Findability: Ensure that all dataset components are tagged and indexed   for easy discoverability within the research community.</li> <li>Accessibility: Provide an open-access platform where researchers can   securely access and download data for AI model training and validation.</li> <li>Interoperability: Structure data in widely accepted formats, facilitating   cross-platform compatibility and collaboration.</li> <li>Reusability: Design data with future adaptability in mind, enabling its   application across a variety of oncology research initiatives.</li> </ul>"},{"location":"Overview/ProjectJustification/","title":"Project Justification","text":"<p>Med-ImageNet Overview</p> <p>Med-ImageNet addresses a major gap: a standardized, accessible, large-scale imaging dataset specifically for AI in oncology.</p> <p>Existing imaging datasets are fragmented, varying widely in quality, format, and annotation, which complicates AI model training and reliability.</p>"},{"location":"Overview/ProjectJustification/#current-gaps-in-medical-imaging-data","title":"Current Gaps in Medical Imaging Data","text":"<ul> <li>Data Silos: Medical imaging data is often siloed within institutions,   limiting external access.</li> <li>Annotation Issues: Datasets lack detailed annotation required   for advanced AI tasks like auto-segmentation and treatment planning.</li> <li>Curation and Accessibility: Inadequate curation and   accessibility hinder the application of machine learning for accurate cancer   diagnosis and treatment.</li> </ul>"},{"location":"Overview/ProjectJustification/#need-for-standardization-in-ai-research","title":"Need for Standardization in AI Research","text":"<ul> <li>Consistency Across Datasets: Standardization is essential for   ensuring that AI models can perform reliably across diverse datasets. Without   consistent data, models risk overfitting to specific datasets, limiting their   broader applicability.</li> <li>Global Collaboration: A standardized framework   allows researchers worldwide to access uniform data, enhancing collaboration   and accelerating advancements in cancer treatment and AI development.</li> </ul>"},{"location":"Overview/ProjectJustification/#impact-on-cancer-research-and-treatment","title":"Impact on Cancer Research and Treatment","text":"<ul> <li>Enhanced Predictive Power: Access to a large,   standardized dataset boosts the predictive accuracy of AI models, helping   clinicians make better-informed treatment decisions.</li> <li>Improved Patient Outcomes: With more reliable AI models,   treatment planning can be personalized, leading to better outcomes and more   efficient resource allocation in oncology care.</li> </ul>"},{"location":"Overview/ResearchObjectivesAims/","title":"Research Objectives and Aims","text":""},{"location":"Overview/ResearchObjectivesAims/#primary-goal","title":"Primary Goal","text":"<p>Develop an open-access, standardized medical imaging dataset specifically curated for cancer research and AI applications in oncology.</p>"},{"location":"Overview/ResearchObjectivesAims/#specific-objectives","title":"Specific Objectives","text":"<ul> <li>Data Curation and Annotation: Establish robust pipelines for data   collection, curation, and high-quality annotation to support machine learning   tasks in cancer diagnosis and treatment.</li> <li>Med-ImageTools Development: Create a suite of tools to streamline data   standardization, facilitating widespread adoption and usability of the   Med-ImageNet dataset.</li> <li>AI Model Support: Enable training and validation of AI models for   applications like tumor segmentation, treatment planning, and outcome   prediction.</li> </ul>"},{"location":"Overview/ResearchObjectivesAims/#long-term-vision","title":"Long-term Vision","text":"<p>Establish Med-ImageNet as the gold standard resource for AI-driven cancer research, encouraging global collaboration and advancing personalized oncology care.</p>"}]}
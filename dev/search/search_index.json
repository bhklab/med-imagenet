{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"ImagingFormats/","title":"Medical Image Formats","text":""},{"location":"ImagingFormats/#introduction","title":"Introduction","text":"<p>A medical image is a digital representation of the internal structure or function of an anatomic region, typically presented as an array of picture elements called pixels (2D) or voxels (3D). This representation is a discrete mapping of numerical values to positions in space.</p>"},{"location":"ImagingFormats/#medical-image-metadata","title":"Medical Image Metadata","text":"<p>Medical images often come with metadata, which provides additional information about the image. This metadata is usually stored at the beginning of the image file as a \"header.\"</p>"},{"location":"ImagingFormats/#common-metadata-fields","title":"Common Metadata Fields","text":"<ul> <li>Image dimensions: Width, height, depth</li> <li>Voxel size: Spacing between voxels</li> <li>Origin: Location of the first voxel</li> <li>Orientation: Direction of x, y, and z axes</li> <li>Pixel depth: Bytes used to represent each voxel intensity</li> <li>Data type: Integer, floating-point, etc.</li> </ul> <p>add diagram showing a sample header with key metadata fields</p>"},{"location":"ImagingFormats/#pixel-data","title":"Pixel Data","text":"<p>The pixel data in a medical image file represents the actual image values, stored in a format specific to the image file.</p> <ul> <li>In fixed-size header formats, pixel data follows the header directly.</li> <li>In other formats, a marker or tag indicates the start of pixel data.</li> </ul>"},{"location":"ImagingFormats/#pixel-data-size","title":"Pixel Data Size","text":"\\[ \\text{Pixel Data Size} = \\text{Rows} \\times \\text{Columns} \\times \\text{Pixel Depth (Bytes)} \\times \\text{Number of Frames} \\]"},{"location":"ImagingFormats/#image-file-size","title":"Image File Size","text":"\\[ \\text{Image File Size} = \\text{Header Size} + \\text{Pixel Data Size} \\] Example Calculation: <p>For a DICOM image with the following parameters:</p> Parameter Value Rows 512 Columns 512 Pixel Depth 2 bytes (16-bit image) Number of Frames 32 (32 slices) \\[ \\text{Pixel Data Size} = 512 \\times 512 \\times 2 \\times 32 = 16,777,216 \\text{ bytes (or 16 MB)} \\] <p>Assuming the header size for this DICOM file is 1,024 bytes:</p> \\[ \\text{Image File Size} = 1,024 \\text{ bytes} + 16,777,216 \\text{ bytes} = 16,778,240 \\text{ bytes (or 16.01 MB)} \\]"},{"location":"ImagingFormats/#medical-image-file-formats","title":"Medical Image File Formats","text":""},{"location":"ImagingFormats/#categories-of-medical-image-formats","title":"Categories of Medical Image Formats","text":"<ol> <li> <p>Standardization Formats: Standardize images from diagnostic modalities.</p> <ul> <li>Example: DICOM</li> </ul> </li> <li> <p>Post-Processing Formats: Facilitate and strengthen post-processing analysis.</p> <ul> <li>Examples: Analyze, NIfTI, MINC</li> </ul> </li> </ol>"},{"location":"ImagingFormats/#configurations-for-storing-medical-images","title":"Configurations for Storing Medical Images","text":"<ul> <li> <p>Single File: Contains both metadata and image data, with metadata stored   at the beginning.</p> <ul> <li>Examples: DICOM, MINC, NIfTI</li> </ul> </li> <li> <p>Two Files: Metadata and image data stored separately.</p> <ul> <li>Example: Analyze (.hdr and .img)</li> </ul> </li> </ul> <p>add diagram comparing single file vs. two-file configurations</p>"},{"location":"ImagingFormats/DICOM/","title":"DICOM (Digital Imaging and Communications in Medicine)","text":"<p>TODO: add introduction to DICOM</p> <p>TODO: Add references if using images from online </p> <p></p> <p></p>"},{"location":"ImagingFormats/nifti/","title":"Nifti Format","text":"<p>https://nipy.org/nibabel/coordinate_systems.html https://nipy.org/nibabel/nifti_images.html NIFTI first poster: https://nifti.nimh.nih.gov/nifti-1/documentation/hbm_nifti_2004.pdf NIfTI structure diagram: https://nifti.nimh.nih.gov/nifti-1/documentation/nifti1diagrams_v2.pdf</p>"},{"location":"ImagingFormats/nifti/#introduction-to-nifti","title":"Introduction to NIfTI","text":"<p>The NIfTI (Neuroimaging Informatics Technology Initiative) format is a derivative of the ANALYZE format, which was originally developed for medical imaging.</p>"},{"location":"ImagingFormats/nifti/#why-nifti","title":"Why NIfTI?","text":"<p>Before NIfTI, medical imaging data was stored in a variety of formats,  including ANALYZE, MINC, and DICOM.</p> <ul> <li>ANALYZE<ul> <li>ANALYZE is a proprietary format developed by the Mayo Clinic.</li> <li>ANALYZE files are not widely supported and are often difficult to work with.</li> </ul> </li> <li>MINC<ul> <li>MINC (Medical Image NetCDF) is a newer format developed by the National  Institutes of Health (NIH).</li> <li>MINC files are widely supported and can be easily shared and distributed.</li> </ul> </li> <li>DICOM<ul> <li>DICOM (Digital Imaging and Communications in Medicine) is a standardized  format for medical imaging data.</li> <li>DICOM files are widely supported and can be easily shared and distributed.</li> </ul> </li> </ul>"},{"location":"ImagingFormats/nifti/#references","title":"References","text":"<ol> <li>Medical Image File Formats, Michele Larobina, 2014.</li> <li>https://brainder.org/2012/09/23/the-nifti-file-format/</li> <li>http://www.cognitive-antics.net/2014/03/04/nifti-plain-and-simple/</li> </ol>"},{"location":"Introduction/Challenges/","title":"Challenges in Medical Imaging Standardization","text":"<p>Standardizing medical imaging data for AI applications presents several challenges:</p> <ul> <li>Variability in Imaging Modalities: Different imaging techniques (e.g., MRI,   CT, PET) produce data with distinct characteristics, making uniform   standardization difficult.</li> <li>Inconsistent Metadata: Metadata formats vary across institutions and   devices, complicating the integration of diverse datasets.</li> <li>Resolution and Quality Differences: Variations in image resolution and   quality across sources can affect model training, as AI models are sensitive   to inconsistencies in input data.</li> <li>Interoperability Issues: Lack of standardized file formats and data   structures hinders interoperability between platforms and research tools.</li> <li>Data Annotation Challenges: Ensuring consistency in annotation across   large datasets is resource-intensive, requiring expert input and validation.</li> </ul>"},{"location":"Introduction/EthicalConsiderations/","title":"Ethical Considerations in AI-driven Cancer Research","text":"<p>Developing AI models for cancer research introduces important ethical considerations:</p> <ul> <li>Bias in Data Representation: Ensuring diverse representation in the dataset   is essential to prevent AI models from inheriting biases that could impact   underrepresented groups.</li> <li>Transparency and Explainability: AI models should be transparent and   interpretable, allowing clinicians to understand the basis of AI-driven   recommendations.</li> <li>Informed Consent: Patients\u2019 consent for the use of their medical images   in research must be clearly defined, especially when sharing data across   institutions.</li> <li>Accountability in Decision-Making: AI models used in clinical settings must   have clear accountability guidelines to manage potential errors and adverse   outcomes.</li> <li>Equitable Access to AI Innovations: The benefits of AI-driven advancements   should be accessible across various healthcare settings, including those   with limited resources.</li> </ul>"},{"location":"Introduction/EvaluationValidation/","title":"Evaluation and Validation Framework for AI Models","text":"<p>To ensure the reliability and accuracy of AI models trained on Med-ImageNet, a rigorous evaluation and validation framework is implemented:</p> <ul> <li>Benchmark Datasets: Provides standardized benchmark datasets within   Med-ImageNet to evaluate model performance across common metrics.</li> <li>Cross-validation Protocols: Supports cross-validation to verify model   robustness and prevent overfitting, ensuring that models generalize well   across different patient groups.</li> <li>Performance Metrics: Includes metrics for evaluating segmentation   accuracy, predictive power, and clinical relevance of AI models.</li> <li>Human-in-the-Loop Validation: Allows experts to review and validate AI   model outputs, ensuring that predictions are clinically meaningful.</li> <li>Continuous Model Improvement: Framework supports ongoing model   evaluation, with feedback loops to integrate new data and improve   performance over time.</li> </ul>"},{"location":"Introduction/ImageNet/","title":"ImageNet: Transforming Computer Vision","text":"<p>This content was written by an LLM</p> <p>This content was written by an LLM and requires a thorough review and editing to ensure accuracy and relevance before publishing.</p>"},{"location":"Introduction/ImageNet/#overview-what-is-imagenet","title":"Overview: What is ImageNet?","text":"<p>ImageNet is a massive visual database created for use in visual object recognition research. With over 14 million labeled images across thousands of categories, ImageNet serves as the backbone for many advancements in computer vision.</p> <p>TODO: add image/diagram of ImageNet categories and dataset structure</p>"},{"location":"Introduction/ImageNet/#the-impact-of-imagenet-on-computer-vision","title":"The Impact of ImageNet on Computer Vision","text":""},{"location":"Introduction/ImageNet/#a-benchmark-for-innovation","title":"A Benchmark for Innovation","text":"<p>ImageNet set a new standard for comparing and evaluating the performance of image recognition algorithms. By establishing a consistent benchmark, ImageNet fostered rapid advancements across the field of computer vision.</p>"},{"location":"Introduction/ImageNet/#the-imagenet-large-scale-visual-recognition-challenge-ilsvrc","title":"The ImageNet Large Scale Visual Recognition Challenge (ILSVRC)","text":"<p>The annual ILSVRC competition has been a major driver of progress. Each year, researchers compete to push the boundaries of image recognition, leading to breakthroughs that have revolutionized AI and deep learning. These innovations have gone beyond image recognition, impacting diverse fields in artificial intelligence and machine learning.</p> <p>TODO: add image/diagram of ILSVRC competition timeline and key milestones</p>"},{"location":"Introduction/ImageNet/#key-breakthroughs-powered-by-imagenet","title":"Key Breakthroughs Powered by ImageNet","text":""},{"location":"Introduction/ImageNet/#alexnet-the-catalyst-for-cnns-2012","title":"AlexNet: The Catalyst for CNNs (2012)","text":"<ul> <li>Achievement: First deep CNN to win ILSVRC, showcasing the potential of   convolutional neural networks (CNNs) for image classification.</li> <li>Impact: Paved the way for CNN architectures, proving their power on a   large-scale dataset.</li> </ul> <p>TODO: add image/diagram of AlexNet architecture</p>"},{"location":"Introduction/ImageNet/#vggnet-deep-networks-simplified-2014","title":"VGGNet: Deep Networks Simplified (2014)","text":"<ul> <li>Achievement: VGGNet demonstrated that increasing network depth can   improve performance.</li> <li>Key Feature: Simple and uniform architecture that added depth without   complexity.</li> </ul> <p>TODO: add image showing VGGNet depth and structure</p>"},{"location":"Introduction/ImageNet/#resnet-the-power-of-residual-learning-2015","title":"ResNet: The Power of Residual Learning (2015)","text":"<ul> <li>Achievement: Introduced the concept of residual connections, making it   possible to train ultra-deep networks.</li> <li>Impact: Enabled breakthroughs in deep learning by overcoming vanishing   gradient issues.</li> </ul> <p>TODO: add image/diagram of residual learning concept in ResNet</p>"},{"location":"Introduction/ImageNet/#yolo-you-only-look-once-real-time-object-detection-2016","title":"YOLO (You Only Look Once): Real-time Object Detection (2016)","text":"<ul> <li>Achievement: Developed a highly efficient real-time object detection   system that uses pre-trained ImageNet models.</li> <li>Impact: Revolutionized object detection, making it faster and more   accessible for applications.</li> </ul> <p>TODO: add image/diagram of YOLO\u2019s object detection in action</p>"},{"location":"Introduction/ImageNet/#mobilenet-lightweight-models-for-mobile-applications-2017","title":"MobileNet: Lightweight Models for Mobile Applications (2017)","text":"<ul> <li>Achievement: Optimized for mobile and embedded devices, leveraging   ImageNet for efficient image recognition.</li> <li>Impact: Brought advanced image recognition to mobile applications,   enabling real-time processing on low-power devices.</li> </ul> <p>TODO: add image/diagram of MobileNet architecture and mobile applications</p>"},{"location":"Introduction/ImageNet/#conclusion-the-lasting-influence-of-imagenet","title":"Conclusion: The Lasting Influence of ImageNet","text":"<p>ImageNet has been foundational in developing computer vision and deep learning technologies. Its role in creating a common benchmark and encouraging innovation through the ILSVRC has led to innovations that extend far beyond image recognition, impacting diverse areas of AI and machine learning. The dataset's influence will continue to shape the landscape of computer vision for years to come.</p> <p>TODO: add image summarizing the impact of ImageNet on AI and machine learning fields</p>"},{"location":"Introduction/ImageNet/#extra-resources","title":"Extra Resources","text":"<ul> <li>ImageNet: A Large-Scale Hierarchical Image Database</li> <li>ImageNet Large Scale Visual Recognition Challenge (ILSVRC)</li> <li>ImageNet: A Large Scale Hierarchical Image Database</li> <li>ImageNet: A Large Scale Hierarchical Image Database</li> </ul>"},{"location":"Introduction/MedImageTools_Specification/","title":"Technical Specifications of MedImage-Tools","text":"<p>MedImage-Tools is designed to streamline the standardization and processing of medical imaging data for AI applications.</p> <p>Key specifications include:</p> <ul> <li>Automated Data Standardization: Tools to automatically convert diverse   imaging formats and metadata into a unified format compatible with Med-ImageNet.</li> <li>Annotation Interface: A user-friendly interface for precise image   annotation, allowing researchers to label and segment data consistently.</li> <li>Scalability: Optimized to handle large datasets efficiently, with support   for batch processing and parallel computations.</li> <li>Customizable Pipelines: Provides modular pipeline components that can be   tailored to specific research needs, including options for preprocessing,   augmentation, and validation.</li> <li>Integration with FAIR Principles: Designed to ensure data is Findable,   Accessible, Interoperable, and Reusable, supporting easy sharing and   collaboration across research teams.</li> </ul>"},{"location":"Overview/","title":"Med-ImageNet: Open-source Medical Imaging Data Curation for Large-scale AI","text":"<p>This documentation is a work in progress.</p> <p>The Med-ImageNet project is currently under development, and this documentation is being updated to reflect the latest progress and features.</p> <p>Please check back for updates and additional content.</p>"},{"location":"Overview/#project-description","title":"Project Description","text":"<p>Med-ImageNet is a transformative framework aiming to facilitate access to standardized medical imaging dataset for cancer research and clinical AI applications.</p>"},{"location":"Overview/#key-information","title":"Key Information","text":"<ul> <li> <p>\ud83d\uddbc Project Title: Med-ImageNet</p> </li> <li> <p>\ud83e\uddec Objective:  Standardize and curate oncology imaging data to support AI-driven cancer research, focusing on auto-segmentation, treatment planning, and monitoring.</p> </li> <li> <p>\ud83c\udf10 Significance: Tackles the lack of standardized healthcare imaging data, making data FAIR (Findable, Accessible, Interoperable, and Reusable) for machine learning applications.</p> </li> <li> <p>\ud83d\udcbb Innovations: Develops MedImage-Tools for data standardization, providing a comprehensive, open-source dataset for cancer imaging.</p> </li> <li> <p>\ud83c\udf0d Equity and Inclusion: Prioritizes data inclusivity by representing diverse populations in cancer research.</p> </li> <li> <p>\ud83e\udd1d Collaboration: Engages with the AI and medical communities to foster collaboration and innovation in cancer research.</p> </li> </ul>"},{"location":"Overview/AI_Applications/","title":"AI Applications in Medical Imaging","text":""},{"location":"Overview/AI_Applications/#auto-segmentation-and-labeling","title":"Auto-Segmentation and Labeling","text":"<ul> <li>Automated Segmentation: Utilize Med-ImageNet data to train models that   can perform automatic segmentation of tumors and relevant structures within   medical images, reducing the time and effort required for manual labeling.</li> <li>Annotation Accuracy: Ensure that auto-segmentation tools produce precise   and clinically relevant boundaries, enhancing the quality of downstream AI   applications.</li> <li>Model Validation: Implement rigorous validation processes to assess the   reliability and accuracy of segmentation models, making them suitable for   clinical and research applications.</li> </ul>"},{"location":"Overview/AI_Applications/#treatment-planning-and-monitoring","title":"Treatment Planning and Monitoring","text":"<ul> <li>AI-driven Planning: Enable AI models trained on Med-ImageNet data to   support personalized treatment planning by identifying key anatomical   features and potential risks.</li> <li>Patient Monitoring: Leverage imaging data to monitor treatment progress   and detect early signs of relapse or treatment response, enabling timely   interventions.</li> <li>Outcome Prediction: Develop models that use imaging features to predict   patient outcomes, supporting oncologists in making data-driven treatment   decisions.</li> </ul>"},{"location":"Overview/AI_Applications/#open-ml-challenge-for-head-and-neck-cancer","title":"Open ML Challenge for Head and Neck Cancer","text":"<ul> <li>Challenge Objective: Host a public machine learning challenge focused on   head and neck cancer segmentation and analysis to encourage innovation and   improve model accuracy.</li> <li>Data Access and Submission: Provide participants with access to   anonymized Med-ImageNet data for training and testing, with submissions   evaluated on segmentation accuracy and clinical relevance.</li> <li>Advancing Model Generalizability: Use the challenge to identify models   that generalize well across diverse data, with high potential for clinical   implementation.</li> </ul>"},{"location":"Overview/Methodology/","title":"Methodology","text":""},{"location":"Overview/Methodology/#data-collection-and-curation-process","title":"Data Collection and Curation Process","text":"<ul> <li>Source Identification: Identify and collect diverse imaging data from   trusted sources, ensuring a broad representation of cancer types and   demographic groups.</li> <li>Data Cleaning and Preprocessing: Implement rigorous data cleaning to   remove inconsistencies and prepare images for standardized processing.</li> <li>Annotation Standards: Apply consistent annotation protocols across all   datasets, with expert validation to ensure quality and reliability.</li> </ul>"},{"location":"Overview/Methodology/#medimage-tools-development","title":"MedImage-Tools Development","text":"<ul> <li>Tool Design: Develop tools that streamline the standardization process,   allowing researchers to easily convert raw imaging data into a format   compatible with Med-ImageNet standards.</li> <li>Automation and Scalability: Design MedImage-Tools with automation   capabilities to handle large-scale data efficiently, ensuring the dataset   remains up-to-date with minimal manual intervention.</li> </ul>"},{"location":"Overview/Methodology/#integration-of-fair-principles","title":"Integration of FAIR Principles","text":"<ul> <li>Findability: Ensure that all dataset components are tagged and indexed   for easy discoverability within the research community.</li> <li>Accessibility: Provide an open-access platform where researchers can   securely access and download data for AI model training and validation.</li> <li>Interoperability: Structure data in widely accepted formats, facilitating   cross-platform compatibility and collaboration.</li> <li>Reusability: Design data with future adaptability in mind, enabling its   application across a variety of oncology research initiatives.</li> </ul>"},{"location":"Overview/ProjectJustification/","title":"Project Justification","text":"<p>Abstract</p> <p>Med-ImageNet addresses a major gap: a standardized framework for accessible, large-scale imaging datasets specifically for AI in oncology.</p> <p>Existing imaging datasets are fragmented, varying widely in quality, format, and annotation, which complicates AI model training and reliability.</p>"},{"location":"Overview/ProjectJustification/#current-gaps-in-medical-imaging-data","title":"Current Gaps in Medical Imaging Data","text":"<ul> <li> <p>Data Silos: Medical imaging data is often siloed within institutions,   limiting external access.</p> </li> <li> <p>Annotation Issues: Datasets lack detailed annotation required   for advanced AI tasks like auto-segmentation and treatment planning.</p> </li> <li> <p>Curation and Accessibility: Inadequate curation and   accessibility hinder the application of machine learning for accurate cancer   diagnosis and treatment.</p> </li> </ul>"},{"location":"Overview/ProjectJustification/#need-for-standardization-in-ai-research","title":"Need for Standardization in AI Research","text":"<ul> <li> <p>Consistency Across Datasets: Standardization is essential for   ensuring that AI models can perform reliably across diverse datasets. Without   consistent data, models risk overfitting to specific datasets, limiting their   broader applicability.</p> </li> <li> <p>Global Collaboration: A standardized framework   allows researchers worldwide to access uniform data, enhancing collaboration   and accelerating advancements in cancer treatment and AI development.</p> </li> </ul>"},{"location":"Overview/ProjectJustification/#impact-on-cancer-research-and-treatment","title":"Impact on Cancer Research and Treatment","text":"<ul> <li> <p>Enhanced Predictive Power: Access to a large,   standardized dataset boosts the predictive accuracy of AI models, helping   clinicians make better-informed treatment decisions.</p> </li> <li> <p>Improved Patient Outcomes: With more reliable AI models,   treatment planning can be personalized, leading to better outcomes and more   efficient resource allocation in oncology care.</p> </li> </ul>"},{"location":"Overview/ResearchObjectivesAims/","title":"Research Objectives and Aims","text":""},{"location":"Overview/ResearchObjectivesAims/#primary-goal","title":"Primary Goal","text":"<p>Develop an open-access, standardized medical imaging dataset specifically curated for cancer research and AI applications in oncology.</p>"},{"location":"Overview/ResearchObjectivesAims/#specific-objectives","title":"Specific Objectives","text":"<ol> <li> <p>Data Curation and Annotation:</p> <p>Establish robust pipelines for data collection, curation, and high-quality annotation to support machine learning tasks in cancer diagnosis and treatment.</p> </li> <li> <p>Med-ImageTools Development:</p> <p>Create a suite of tools to streamline data standardization, facilitating widespread adoption and usability of the Med-ImageNet dataset.</p> </li> <li> <p>AI Model Support:</p> <p>Enable training and validation of AI models for applications like tumor segmentation, treatment planning, and outcome prediction.</p> </li> </ol>"},{"location":"Overview/ResearchObjectivesAims/#long-term-vision","title":"Long-term Vision","text":"<p>Establish Med-ImageNet as the gold standard resource for AI-driven cancer research, encouraging global collaboration and advancing personalized oncology care.</p>"},{"location":"devnotes/","title":"A lot of these devnotes are just braindumps","text":"<p>As they become more coherent, they should be moved to issues / PRs / blog posts within the docs.</p>"},{"location":"devnotes/Med-ImageDB/","title":"Med-ImageDB (Medical Image Database)","text":""},{"location":"devnotes/Med-ImageDB/#description","title":"Description","text":"<p>Med-ImageDB aims to provide a index of sources that provide access to medical images, which can then be used for training and testing machine learning models.</p> <p>The database contains images of various modalities.</p>"},{"location":"devnotes/Med-ImageDB/#sources","title":"Sources","text":"<ul> <li> <p>ziyangwang007/Awesome-Medical-Image-Segmentation-Dataset</p> </li> <li> <p>adalca/medical-datasets</p> </li> <li> <p>aylward.org/open-access-medical-image-repositories</p> </li> <li> <p>m-aryayi/Medical-Imaging-Datasets</p> </li> </ul> <p>This one is actually very thorough and has 600+ links to publications and datasets.</p> <ul> <li>openmedlab/Awesome-Medical-Dataset</li> </ul> <p>Also very thorough and organized.</p>"},{"location":"devnotes/Inspiration/","title":"Inspiration","text":"<p>A collection of resources that relate to this project</p> <ul> <li>Different projects that can be used as inspiration for their code organization, user interface, etc.</li> </ul>"},{"location":"devnotes/Inspiration/amid/","title":"neuro-ml/amid (Awesome Medical Imaging Datasets)","text":"<p>Github repository: neuro-ml/amid</p> <p>Really interesting way they have set up a easy-to-use interface for loading datasets.</p> <p>Pros:</p> <ul> <li>similar user API for each dataset</li> <li>very nice code organization</li> <li>neat code quality</li> </ul> <p>Cons:</p> <ul> <li>Manually created code for each dataset</li> <li>Not very scalable</li> <li>Requires users to download and organize the datasets themselves.</li> </ul>"}]}
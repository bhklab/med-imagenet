{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nbiatoolkit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnbiatoolkit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NBIAClient\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nbiatoolkit'"
     ]
    }
   ],
   "source": [
    "from nbiatoolkit import NBIAClient\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from rich import print\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query the NBIA API\n",
    "\n",
    "## Environment Variables:\n",
    "Add this to a `.env` file in your project directory and add your environment variables:\n",
    "\n",
    "```\n",
    "NBIA_USERNAME=<username>\n",
    "NBIA_PASSWORD=<password>\n",
    "```\n",
    "\n",
    "NOTE: developed this notebook using bhklab's account credentials \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "USERNAME= os.environ.get(\"NBIA_USERNAME\")\n",
    "PASSWORD=os.environ.get(\"NBIA_PASSWORD\")\n",
    "client = NBIAClient(\n",
    "  username=USERNAME,\n",
    "  password=PASSWORD,\n",
    "  return_type=\"dataframe\",\n",
    "  log_level=\"DEBUG\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_path = Path(\"data/nbia_collections.tsv\")\n",
    "\n",
    "if collection_path.exists():\n",
    "    collections = pd.read_csv(collection_path, sep=\"\\t\")\n",
    "else:\n",
    "    collections = client.getCollectionPatientCount()\n",
    "    collections.to_csv(collection_path, sep=\"\\t\", index=False)\n",
    "\n",
    "print(collections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grant Table 1: Data\n",
    "\n",
    "### BHKLAB \n",
    "\n",
    "- QIN-HEADNECK\n",
    "- Head-Neck-PET-CT\n",
    "- CPTAC-HNSCC\n",
    "- HNSCC\n",
    "- HEAD-NECK-RADIOMICS-HN1\n",
    "- HNSCC-3DCT-RT\n",
    "- OPC-Radiomics\n",
    "- TCGA-HNSC\n",
    "- STRUCTSEG19\n",
    "- 18F-FDG PET Radiomics Risk Challenge\n",
    "- HPV Prediction Challenge\n",
    "- PDDCA\n",
    "- RADCURE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bhklab = [\n",
    "    \"QIN-HEADNECK\",\n",
    "    \"Head-Neck-PET-CT\",\n",
    "    \"CPTAC-HNSCC\",\n",
    "    \"HNSCC\",\n",
    "    \"HEAD-NECK-RADIOMICS-HN1\",\n",
    "    \"HNSCC-3DCT-RT\",\n",
    "    \"TCGA-HNSC\",\n",
    "    \"RADCURE\",\n",
    "    \"OPC-Radiomics\",\n",
    "    \"STRUCTSEG19\",\n",
    "    \"18F-FDG PET Radiomics Risk Challenge\",\n",
    "    \"HPV Prediction Challenge\",\n",
    "    \"PDDCA\",\n",
    "]\n",
    "wanglab = [\n",
    "    \"CPTAC-CCRCC\",\n",
    "    \"CPTAC-PDA\",\n",
    "    \"CPTAC-UCEC\",\n",
    "    \"CT Lymph Nodes\",\n",
    "    \"TCGA-BLCA\",\n",
    "    \"TCGA-KIRC\",\n",
    "    \"TCGA-LIHC\",\n",
    "    \"TCGA-OV\",\n",
    "    \"TCGA-STAD\",\n",
    "    \"Pancreas-CT\",\n",
    "    \"ct org\",\n",
    "    \"KiTS\",\n",
    "    \"Pancreatic-CT-CBCT-SEG\",\n",
    "    \"CPTAC-SAR\",\n",
    "    \"TCGA-KICH\",\n",
    "    \"TCGA-KIRP\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "missing_from_tcia = defaultdict(list)\n",
    "\n",
    "# Continue from the last code cell\n",
    "for dataset in bhklab:\n",
    "    if not collections['Collection'].str.contains(dataset, case=False).any():\n",
    "        missing_from_tcia['bhklab'].append(dataset)\n",
    "\n",
    "for dataset in wanglab:\n",
    "    if not collections['Collection'].str.contains(dataset, case=False).any():\n",
    "        missing_from_tcia['wanglab'].append(dataset)\n",
    "\n",
    "# Print the datasets that are missing\n",
    "print(\"Datasets not found in TCIA collections:\")\n",
    "print(missing_from_tcia)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes :\n",
    "\n",
    "### OPC-Radiomics\n",
    "\n",
    "Note from website previously on TCIA: \n",
    "\n",
    "\n",
    "> This collection has been deprecated.\n",
    "> Data from the collection formerly called OPC-Radiomics has been updated. \n",
    "> The data are downloadable but no longer viewable in the Cancer Imaging Archive. \n",
    "> Please view the RADCURE page to obtain access to the updated data: https://doi.org/10.7937/J47W-NM11.\n",
    "\n",
    "\n",
    "**Data Location**: \n",
    "`/cluster/projects/radiomics/PublicDatasets/HeadNeck/TCIA-OPC`\n",
    "`/cluster/projects/radiomics/PublicDatasets/HeadNeck/TCIA_OPC-Radiomics`\n",
    "\n",
    "**Source Link**: [https://www.cancerimagingarchive.net/collection/opc-radiomics/](https://www.cancerimagingarchive.net/collection/opc-radiomics/)\n",
    "\n",
    "**Institution**: \"TCIA\"\n",
    "\n",
    "### STRUCTSEG19\n",
    "\n",
    "**Data Location**: `/cluster/projects/radiomics/PublicDatasets/HeadNeck/MICCAI_2019_STRUCTURESEG19`\n",
    "\n",
    "**Source Link**: [https://structseg2019.grand-challenge.org](https://structseg2019.grand-challenge.org)\n",
    "\n",
    "**Institution**: \"MICCAI / Zhejiang Cancer Hospital\"\n",
    "\n",
    "\n",
    "\n",
    "### 18F-FDG PET Radiomics Risk Challenge\n",
    "\n",
    "**Data Location**: `/cluster/projects/radiomics/PublicDatasets/HeadNeck/MICCAI_2018_18F-FDG_PET_Radiomics_Risk_Challenge`\n",
    "\n",
    "**Source Link**:\n",
    "\n",
    "**Institution**: MICCAI / multi-institution\n",
    "\n",
    "###  HPV Prediction Challenge\n",
    "\n",
    "`MICCAI_2016_HPV_Prediction_Challenge` \n",
    "\n",
    "**Data Location**: `/cluster/projects/radiomics/PublicDatasets/HeadNeck/MICCAI_2016_HPV_Prediction_Challenge`\n",
    "\n",
    "**Source Link**:\n",
    "\n",
    "**Institution**: \"MD Anderson CC / MICCAI\"\n",
    "\n",
    "\n",
    "### PDDCA\n",
    "\n",
    "`A Public Domain Database for Computational Anatomy (PDDCA)`\n",
    "\n",
    "**Data Location**: `/cluster/projects/radiomics/PublicDatasets/HeadNeck/A Public Domain Database for Computational Anatomy(PDDCA)`\n",
    "\n",
    "**Source Link**: [https://www.imagenglab.com/newsite/pddca/](https://www.imagenglab.com/newsite/pddca/)\n",
    "\n",
    "**Institution**: \"Harvard / MICCAI\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset collection dataframe to only include our desired datasets\n",
    "datasets = bhklab + wanglab\n",
    "\n",
    "\n",
    "collections = collections[collections['Collection'].str.contains('|'.join(datasets), case=False)].copy()\n",
    "collections['mycollection_name'] = collections['Collection'].str.extract('(' + '|'.join(datasets) + ')', flags=re.IGNORECASE)\n",
    "collections.reset_index(drop=True, inplace=True)\n",
    "collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_lists = []\n",
    "series_metadata_lists = []\n",
    "\n",
    "\n",
    "def clean_name(name):\n",
    "    return name.replace(\" \", \"_\").replace(\"-\", \"_\")\n",
    "\n",
    "\n",
    "data_path = Path(\"data\") / \"collections\"\n",
    "data_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "\n",
    "for i, dataset in enumerate(collections.Collection.unique()):\n",
    "\n",
    "    file_path = data_path / f\"{clean_name(dataset)}.tsv\"\n",
    "\n",
    "    if file_path.exists():\n",
    "        series = pd.read_csv(file_path, sep=\"\\t\")\n",
    "    else:  \n",
    "        print(f\"Would need to get series for {dataset}\")\n",
    "        series = client.getSeries(Collection=dataset)\n",
    "        series.to_csv(file_path, sep=\"\\t\", index=False)\n",
    "\n",
    "    unique_modalities = series.Modality.unique()\n",
    "    body_parts = []\n",
    "    for modality in unique_modalities:\n",
    "        modality_series = series[series.Modality == modality]\n",
    "        \n",
    "        if \"BodyPartExamined\" in modality_series.columns:\n",
    "            # add to body_parts set\n",
    "            body_parts.extend(list(modality_series.BodyPartExamined.dropna().unique())) \n",
    "\n",
    "        metadata = {\n",
    "                \"Collection\": dataset,\n",
    "                \"TotalPatients\": len(series.PatientID.unique()),\n",
    "                \"BodyPartExamined\": \", \".join(set(body_parts)),\n",
    "                \"Modality\": modality,\n",
    "                \"PatientPerModality\": len(modality_series.PatientID.unique()),\n",
    "                \"SeriesPerModality\": len(modality_series),\n",
    "                \"totalSizeGB\": round(sum(modality_series.FileSize) / 1024 ** 3, 2),\n",
    "        }\n",
    "        series_lists.append(metadata)\n",
    "    del series\n",
    "\n",
    "# create a dataframe from the list of dictionaries\n",
    "series_metadata_df = pd.DataFrame(series_lists)\n",
    "series_metadata_df.to_csv(\"data/series_metadata_df.tsv\", index=False, header=True, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataframes = []\n",
    "for file in (data_path).glob(\"*.tsv\"):\n",
    "    df = pd.read_csv(file, sep='\\t')\n",
    "    dataframes.append(df)\n",
    "\n",
    "concatenated_df = pd.concat(dataframes, axis=0, ignore_index=True, sort=False)\n",
    "concatenated_df = concatenated_df.fillna('N/A')\n",
    "concatenated_df.sort_values(by=[\"Collection\", \"PatientID\"], inplace=True)\n",
    "concatenated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "'SeriesInstanceUID', 'StudyInstanceUID', 'Modality', 'SeriesDate',\n",
    "       'SeriesDescription', 'BodyPartExamined', 'SeriesNumber', 'Collection',\n",
    "       'PatientID', 'ImageCount', 'TimeStamp', 'LicenseName', 'LicenseURI',\n",
    "       'CollectionURI', 'FileSize', 'DateReleased', 'StudyDesc', 'StudyDate',\n",
    "       'ThirdPartyAnalysis', 'SoftwareVersions', 'Manufacturer',\n",
    "       'ManufacturerModelName', 'ProtocolName', 'AnnotationsFlag'\n",
    "\"\"\"\n",
    "\n",
    "columns_of_interest = [\n",
    "    \"Collection\",\n",
    "    \"PatientID\",\n",
    "    \"StudyInstanceUID\",\n",
    "    \"Modality\",\n",
    "    \"SeriesInstanceUID\",\n",
    "    \"SeriesNumber\",\n",
    "    \"SeriesDate\",\n",
    "    \"BodyPartExamined\",\n",
    "    \"ImageCount\",\n",
    "    \"TimeStamp\",\n",
    "    \"CollectionURI\",\n",
    "    \"FileSize\",\n",
    "    \"DateReleased\",\n",
    "]\n",
    "\n",
    "subset_df = concatenated_df[columns_of_interest]\n",
    "subset_df.reset_index(drop=True, inplace=True)\n",
    "subset_df.to_csv(\"data/AllSeries.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
